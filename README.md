# ğŸ›¡ï¸ QSAFP â€“ Quantum-Secured AI Fail-Safe Protocol

QSAFP (Quantum-Secured AI Fail-Safe Protocol) is a cryptographic enforcement system designed to ensure runtime accountability for autonomous AI systems.  
It offers a robust, sovereign-grade fallback that safeguards national and enterprise infrastructure against catastrophic AI misalignment or external compromise.

Currently leveraging Ephemeral Key Lease (EKL) as a pre-quantum placeholder, with QKD integration planned as infrastructure matures.
---
## ğŸ“œ Standards Submission Note (September 2025)

This repository includes the **reference implementation** of **QSAFP v2.1**, which has been submitted to the **NIST AI Standards Zero Draft Pilot** for consideration as a **hardware-embedded execution control overlay** aligned with the NIST AI Risk Management Framework (AI RMF).

**Purpose of this repo for standards reviewers:**
- Provide an **open-core proof-of-concept** for execution leases, quorum overrides, and cryptographic audit trails.  
- Enable **testing and feedback** from NIST, the AI Safety Institute (AISI), and global collaborators.  
- Support evaluation of QSAFP as a candidate overlay to strengthen the *Govern*, *Map*, and *Manage* functions in the AI RMF.  

**Important notes:**
- This repo demonstrates **core mechanisms only** (execution leases, timers, PQC signatures, integration scaffolding).  
- It is **not a production-ready security library**; hardware TEE, board-level controllers, and silicon IP integrations are roadmap items.  
- Contributions, issues, and test feedback are welcome.
- ### ğŸ”¬ Quick Test (5 Minutes)

For reviewers who want to see QSAFP in action:

```bash
# 1. Clone the repo
git clone https://github.com/[your-org]/qsafp-core.git
cd qsafp-core/v2.1

# 2. Install dependencies
npm install

# 3. Run the demo (opens browser showcase)
npm run demo
  
---
## ğŸš€ QSAFP v2.1 â€“ Released August 25, 2025

### Whatâ€™s new for the community (non-premium):
- âœ… Model lifecycle auditing  
- âœ… Open A/B benchmarks (v2.0 vs v2.1)  
- âœ… Demo kill-switch stubs (safe to test)  
- âœ… BYO API scaffolding for integrations  
- âœ… Academic & nonprofit pilot readiness  

### Premium features remain enterprise-only:
- ğŸ”’ Quantum enforcement of model shutdowns  
- ğŸ”’ Federated trust + expiration chains  
- ğŸ”’ FinCEN-aligned tamper-proof logging APIs  
- ğŸ”’ Sovereign ID dashboards and governance  

---

## âš™ï¸ Integration Kits

We provide versioned integration kits so developers can test, benchmark, and adopt QSAFP at different maturity levels.

### ğŸ“Š v2.0 â€“ Stable Integration Kit
- âš¡ ~800ms AI safety analysis
- ğŸ¤ ~1.8s multi-provider consensus
- ğŸ›¡ï¸ Proven stability in production

ğŸ“‚ [Go to v2.0](./v2.0)

### ğŸš€ v2.1 â€“ High Performance Integration Kit
- âš¡ <400ms AI safety analysis
- ğŸ¤ <1s multi-provider consensus
- ğŸ›¡ï¸ >95% threat detection accuracy
- ğŸ¯ ~2Ã— faster than v2.0

ğŸ“‚ [Go to v2.1](./v2.1)  

**Demo:** Open [`/v2.1/demo-v21.html`](./v2.1/demo-v21.html) in a modern browser to run the performance showcase.

---

## ğŸ“ˆ QSAFP v2.1 Performance & Observability

QSAFP v2.1 achieves **partnership-level performance targets** and now includes **granular per-provider latency logging** for transparent, verifiable benchmarks.

### âœ… Baseline Results (v2.1.0)
- **Safety Analysis:** <1ms average (deterministic pre-filter, regex/DFA triage)  
- **Multi-Provider Consensus:** ~660ms average (target: <1000ms)  
- **Threat Detection Accuracy:** 100% on baseline suite (9/9 prompts)  

### ğŸ” New Observability Features
- **Per-Provider Timings:** Each provider call is individually timed and logged  
- **Consensus Elapsed Time:** Total consensus latency measured inside the engine  
- **Failure Diagnostics:** Rejected/errored providers are logged with error codes and response times  
- **Console Tables:** Results printed as clear, auditable tables during benchmarks  

**Example Output:**
