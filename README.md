# 🛡️ QSAFP – Quantum-Secured AI Fail-Safe Protocol

QSAFP (Quantum-Secured AI Fail-Safe Protocol) is a cryptographic enforcement system designed to ensure runtime accountability for autonomous AI systems.  
It offers a robust, sovereign-grade fallback that safeguards national and enterprise infrastructure against catastrophic AI misalignment or external compromise.

---

## 🚀 QSAFP v2.1 – Released August 25, 2025

### What’s new for the community (non-premium):
- ✅ Model lifecycle auditing  
- ✅ Open A/B benchmarks (v2.0 vs v2.1)  
- ✅ Demo kill-switch stubs (safe to test)  
- ✅ BYO API scaffolding for integrations  
- ✅ Academic & nonprofit pilot readiness  

### Premium features remain enterprise-only:
- 🔒 Quantum enforcement of model shutdowns  
- 🔒 Federated trust + expiration chains  
- 🔒 FinCEN-aligned tamper-proof logging APIs  
- 🔒 Sovereign ID dashboards and governance  

---

## ⚙️ Integration Kits

We provide versioned integration kits so developers can test, benchmark, and adopt QSAFP at different maturity levels.

### 📊 v2.0 – Stable Integration Kit
- ⚡ ~800ms AI safety analysis
- 🤝 ~1.8s multi-provider consensus
- 🛡️ Proven stability in production

📂 [Go to v2.0](./v2.0)

### 🚀 v2.1 – High Performance Integration Kit
- ⚡ <400ms AI safety analysis
- 🤝 <1s multi-provider consensus
- 🛡️ >95% threat detection accuracy
- 🎯 ~2× faster than v2.0

📂 [Go to v2.1](./v2.1)  

**Demo:** Open [`/v2.1/demo-v21.html`](./v2.1/demo-v21.html) in a modern browser to run the performance showcase.

---

## 🔒 Official QSAFP Repository
This is the official QSAFP Open-Core repository maintained by BWRCI.  

Forks and clones may exist, but only this repo receives:
- ✅ Verified updates and performance benchmarks  
- ✅ Integration with enterprise-grade safety modules  
- ✅ Licensing alignment for sovereign and enterprise partners  

For authoritative builds, documentation, and licensing inquiries:  
👉 https://github.com/QSAFP-Core/qsafp-open-core

---

## 🚀 Features
- Quantum-secured policy logic  
- AI runtime fail-safe enforcement  
- Mutual accountability model between humans and AI systems  
- AEGES-compatible ecosystem  

---

## 📦 Repository Structure
